pval_residuals = c()
input_resp$PreECLSArrest = factor(input_resp$PreECLSArrest)
df0 = input_resp[which((is.na(input_resp$Y) ==FALSE) &(is.na(input_resp$ICUtype) ==FALSE)), c("Y","ICUtype", INPUT_VARS)]
df0 = df0 %>% drop_na()
mod0 <- lm(Y~ ., data= df0[,c("Y", INPUT_VARS)])
mod02 <- lm(Y~ ., data= df0)
df = data.frame(Corrected = mod0$residuals,
ICUtype = df0$ICUtype)
df2 = data.frame(Corrected = mod02$residuals,
ICUtype = df0$ICUtype)
#summary  of the linear regression and ANCOVA
coeffs[i,] =  summary(mod0)$coefficients[,1]
sig_coeffs[i,] =  summary(mod0)$coefficients[,4]
coeffs2[i,] =  summary(mod02)$coefficients[,1]
sig_coeffs2[i,] =  summary(mod02)$coefficients[,4]
pval_residuals <-  rbind(pval_residuals,
c(OUTPUT_VARS[i],
summary(mod02)$coefficients["ICUtypeNon CT-ICU", 4],
anova(mod0, mod02)[2,6])
)
pval_residuals
library(naniar)
install.packages("naniar")
library(naniar)
gg_miss_upset(input)
vis_miss(input)
INPUT_VARS
gg_miss_upset(df0)
gg_miss_upset(input_cardiac[,INPUTS])
vis_miss(input_cardiac[,INPUTS])
ggsave(paste0(FOLDER_PLOTS, "cardiac_missing.pdf"))
vis_miss(input_cardiac[,INPUT_VARS])
ggsave(paste0(FOLDER_PLOTS, "cardiac_missing.pdf"))
shiny::runApp('Dropbox/aerosol_transmission_model')
runApp('Dropbox/aerosol_transmission_model')
max_date = "2020-09-01"
country = "France"
MAX_DATE = as.Date(max_date)
COUNTRY = country
PERIOD_FOR_FITTING = 14
PERIOD_FOR_PREDICTING = 23
NB_OF_CASE_CURVES = 20
DAYS_TO_EVENT = 0
TIME_TO_SYMPTOM_ONSET = 5
TIME_FROM_SYMPT_ONSET_TO_TEST_RESULT = 4
PROPORTION_CASES_DETECTED = 1
# Convert date to numeric
COUNTRY_DATA <- read.csv(file="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv", header=T, sep=",")
COUNTRY_DATA$date <- as.numeric(as.Date(COUNTRY_DATA$date, "%Y-%m-%d"))
# Select the smoothed new cases per million in your country of interest
filename=paste0("prevalence_", COUNTRY, "_data.csv")
chosen_location_data <- COUNTRY_DATA %>%
dplyr::filter((location==COUNTRY) & (date> MAX_DATE - PERIOD_FOR_FITTING)) %>%
dplyr::select(new_cases_smoothed_per_million)
# Select all the other data from other countries which might fit your country of interest
country_data_historic <- filter(COUNTRY_DATA, date< MAX_DATE - PERIOD_FOR_PREDICTING)
# Convert the data to wide format by location name
country_data_historic_wide <- country_data_historic %>%
dplyr::select(date, location, new_cases_smoothed_per_million) %>%
pivot_wider(.,names_from=location, values_from=new_cases_smoothed_per_million)
# Define the difference function
Difference_function <- function(data) {
if(sum(is.na(data))>0){
return(NA)
### might want to
}
sum((data-chosen_location_data$new_cases_smoothed_per_million)^2)
}
library(ggplot2)
#install.packages('doBy', repos='http://cran.us.r-project.org')
#library(doBy, lib="~/R_libs")
library(tidyverse)
#install.packages('slider', lib="~/R_libs", repos='http://cran.us.r-project.org')
library(pbapply)
library('slider')
MAX_DATE = as.Date(max_date)
COUNTRY = country
PERIOD_FOR_FITTING = 14
PERIOD_FOR_PREDICTING = 23
NB_OF_CASE_CURVES = 20
DAYS_TO_EVENT = 0
TIME_TO_SYMPTOM_ONSET = 5
TIME_FROM_SYMPT_ONSET_TO_TEST_RESULT = 4
PROPORTION_CASES_DETECTED = 1
# Convert date to numeric
COUNTRY_DATA <- read.csv(file="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv", header=T, sep=",")
COUNTRY_DATA$date <- as.numeric(as.Date(COUNTRY_DATA$date, "%Y-%m-%d"))
# Select the smoothed new cases per million in your country of interest
filename=paste0("prevalence_", COUNTRY, "_data.csv")
chosen_location_data <- COUNTRY_DATA %>%
dplyr::filter((location==COUNTRY) & (date> MAX_DATE - PERIOD_FOR_FITTING)) %>%
dplyr::select(new_cases_smoothed_per_million)
# Select all the other data from other countries which might fit your country of interest
# Select all the other data from other countries which might fit your country of interest
country_data_historic <- filter(COUNTRY_DATA, date< MAX_DATE - PERIOD_FOR_PREDICTING)
# Convert the data to wide format by location name
country_data_historic_wide <- country_data_historic %>%
dplyr::select(date, location, new_cases_smoothed_per_million) %>%
pivot_wider(.,names_from=location, values_from=new_cases_smoothed_per_million)
# Define the difference function
Difference_function <- function(data) {
if(sum(is.na(data))>0){
return(NA)
### might want to
}
sum((data-chosen_location_data$new_cases_smoothed_per_million)^2)
}
chosen_location_data
chosen_location_data$new_cases_smoothed_per_million
length(chosen_location_data$new_cases_smoothed_per_million)
chosen_location_data <- COUNTRY_DATA %>%
dplyr::filter((location==COUNTRY) & (date> MAX_DATE - PERIOD_FOR_FITTING) &  (date <= MAX_DATE))) %>%
dplyr::select(new_cases_smoothed_per_million)
chosen_location_data <- COUNTRY_DATA %>%
dplyr::filter((location==COUNTRY) & (date> MAX_DATE - PERIOD_FOR_FITTING) &  (date <= MAX_DATE)) %>%
dplyr::select(new_cases_smoothed_per_million)
length(chosen_location_data)
chosen_location_data
dim(chosen_location_data)
chosen_location_data <- COUNTRY_DATA %>%
dplyr::filter((location==COUNTRY) & (date> MAX_DATE - PERIOD_FOR_FITTING) &  (date <= MAX_DATE)) %>%
dplyr::select(new_cases_smoothed_per_million)
# Select all the other data from other countries which might fit your country of interest
country_data_historic <- filter(COUNTRY_DATA, (date> MAX_DATE - PERIOD_FOR_FITTING) &  (date <= MAX_DATE))
# Convert the data to wide format by location name
country_data_historic_wide <- country_data_historic %>%
dplyr::select(date, location, new_cases_smoothed_per_million) %>%
pivot_wider(.,names_from=location, values_from=new_cases_smoothed_per_million)
# Define the difference function
Difference_function <- function(data) {
if(sum(is.na(data))>0){
return(NA)
### might want to
}
sum((data-chosen_location_data$new_cases_smoothed_per_million)^2)
}
# Calculate the differences matrix
pboptions(type = "txt", style = 1, char = "=")
Differences_matrix <- pbapply(country_data_historic_wide[,2:ncol(country_data_historic_wide)],
MARGIN=2,
FUN=function(x){
sapply((PERIOD_FOR_FITTING):length(x),
function(d){Difference_function(x[(d-PERIOD_FOR_FITTING + 1):d])})
}
)
# Format, date and melt the differences matrix to a long dataframe
Differences_matrix = data.frame(Differences_matrix)
Differences_matrix$date = unlist(country_data_historic_wide[PERIOD_FOR_FITTING:nrow(country_data_historic_wide),1],
use.names = FALSE)
diff_vec = reshape2::melt(as_tibble(Differences_matrix), id.vars=c("date"))
# Find and select the end time points of the closes case curves
closest_case_curves <- sort(diff_vec$value,  decreasing = FALSE,index.return=TRUE)$ix[1:NB_OF_CASE_CURVES]
diff_vec2 = diff_vec[closest_case_curves, ]
# Find all the case data before and after the last date of the best fit curves
full_closest_case_curves = sapply(1:NB_OF_CASE_CURVES, function(x){
print(gsub(".", " ", toString(diff_vec2$variable[x]), fixed = TRUE))
unlist(COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING) %>%
dplyr::select(new_cases_smoothed_per_million), use.names = FALSE)
})
# Convert to dataframe, add a time column and melt to long format
full_closest_case_curves <- data.frame(full_closest_case_curves)
full_closest_case_curves$time = seq(from=-PERIOD_FOR_FITTING,
to=PERIOD_FOR_PREDICTING,
by=1)
melted_case_curves <- reshape2::melt(full_closest_case_curves,
id.vars="time")
# Calculate the mean and standard deviation at each timepoint
Summarised_case_predictions <- melted_case_curves %>%
group_by(time) %>%
dplyr::summarise(prevalence=mean(value/1e6), sd_prevalence=sd(value/1e6))
# Parametrise the delay between infections and cases being reported
Infection_to_test_result_delay <- TIME_TO_SYMPTOM_ONSET + TIME_FROM_SYMPT_ONSET_TO_TEST_RESULT
#Calculate the date of the cases
Summarised_case_predictions$Date_of_cases=as.Date(Summarised_case_predictions$time +
max(COUNTRY_DATA$date),
origin = "1970-01-01")
# Create a dataframe of infection
Infections_df <- data.frame(Date_of_infection=Summarised_case_predictions$Date_of_cases - Infection_to_test_result_delay,
Infection_prevalence=Summarised_case_predictions$prevalence/PROPORTION_CASES_DETECTED,
sd_Infection_prevalence=Summarised_case_predictions$sd_prevalence/PROPORTION_CASES_DETECTED)
# Reverse sort by date of infection
sorted_case_predictions <- Infections_df[order(Infections_df$Date_of_infection, decreasing=T), ]
# save as csv file
#write.csv(x=sorted_case_predictions, file=filename)
Differences_matrix = data.frame(Differences_matrix)
Differences_matrix$date = unlist(country_data_historic_wide[PERIOD_FOR_FITTING:nrow(country_data_historic_wide),1],
use.names = FALSE)
diff_vec = reshape2::melt(as_tibble(Differences_matrix), id.vars=c("date"))
# Find and select the end time points of the closes case curves
closest_case_curves <- sort(diff_vec$value,  decreasing = FALSE,index.return=TRUE)$ix[1:NB_OF_CASE_CURVES]
diff_vec2 = diff_vec[closest_case_curves, ]
full_closest_case_curves = sapply(1:NB_OF_CASE_CURVES, function(x){
print(gsub(".", " ", toString(diff_vec2$variable[x]), fixed = TRUE))
unlist(COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING) %>%
dplyr::select(new_cases_smoothed_per_million), use.names = FALSE)
})
diff_vec2
Differences_matrix
diff_vec = reshape2::melt(as_tibble(Differences_matrix), id.vars=c("date"))
# Find and select the end time points of the closes case curves
closest_case_curves <- sort(diff_vec$value,  decreasing = FALSE,index.return=TRUE)$ix[1:NB_OF_CASE_CURVES]
Differences_matrix <- pbapply(country_data_historic_wide[,2:ncol(country_data_historic_wide)],
MARGIN=2,
FUN=function(x){
sapply((PERIOD_FOR_FITTING):length(x),
function(d){Difference_function(x[(d-PERIOD_FOR_FITTING + 1):d])})
}
)
Differences_matrix
country_data_historic_wide[,2:ncol(country_data_historic_wide)]
Differences_matrix <- apply(country_data_historic_wide[,2:ncol(country_data_historic_wide)],
MARGIN=2,
FUN=function(x){
sapply((PERIOD_FOR_FITTING):length(x),
function(d){Difference_function(x[(d-PERIOD_FOR_FITTING + 1):d])})
}
)
Differences_matri
Differences_matrix
x = country_data_historic_wide[,2]
length(x)
length(unlist(x))
# Select all the other data from other countries which might fit your country of interest
country_data_historic <- filter(COUNTRY_DATA, (date < MAX_DATE - PERIOD_FOR_FITTING))
# Convert the data to wide format by location name
country_data_historic_wide <- country_data_historic %>%
dplyr::select(date, location, new_cases_smoothed_per_million) %>%
pivot_wider(.,names_from=location, values_from=new_cases_smoothed_per_million)
# Define the difference function
Difference_function <- function(data) {
if(sum(is.na(data))>0){
return(NA)
### might want to
}
sum((data-chosen_location_data$new_cases_smoothed_per_million)^2)
}
pboptions(type = "txt", style = 1, char = "=")
Differences_matrix <- apply(country_data_historic_wide[,2:ncol(country_data_historic_wide)],
MARGIN=2,
FUN=function(x){
sapply((PERIOD_FOR_FITTING):length(x),
function(d){Difference_function(x[(d-PERIOD_FOR_FITTING + 1):d])})
}
)
Differences_matrix
View(Differences_matrix)
source('~/Dropbox/aerosol_transmission_model/covid_case_predictions.R')
compute_prevalence("2020-09-01", "France")
MAX_DATE = as.Date(max_date)
COUNTRY = country
PERIOD_FOR_FITTING = 14
PERIOD_FOR_PREDICTING = 23
NB_OF_CASE_CURVES = 20
DAYS_TO_EVENT = 0
TIME_TO_SYMPTOM_ONSET = 5
TIME_FROM_SYMPT_ONSET_TO_TEST_RESULT = 4
PROPORTION_CASES_DETECTED = 1
# Convert date to numeric
COUNTRY_DATA <- read.csv(file="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv", header=T, sep=",")
COUNTRY_DATA$date <- as.numeric(as.Date(COUNTRY_DATA$date, "%Y-%m-%d"))
# Select the smoothed new cases per million in your country of interest
filename=paste0("prevalence_", COUNTRY, "_data.csv")
chosen_location_data <- COUNTRY_DATA %>%
dplyr::filter((location==COUNTRY) & (date> MAX_DATE - PERIOD_FOR_FITTING) &  (date <= MAX_DATE)) %>%
dplyr::select(new_cases_smoothed_per_million)
# Select all the other data from other countries which might fit your country of interest
country_data_historic <- filter(COUNTRY_DATA, (date < MAX_DATE - PERIOD_FOR_FITTING))
# Convert the data to wide format by location name
country_data_historic_wide <- country_data_historic %>%
dplyr::select(date, location, new_cases_smoothed_per_million) %>%
pivot_wider(.,names_from=location, values_from=new_cases_smoothed_per_million)
# Define the difference function
Difference_function <- function(data) {
if(sum(is.na(data))>0){
return(NA)
### might want to
}
sum((data-chosen_location_data$new_cases_smoothed_per_million)^2)
}
# Calculate the differences matrix
pboptions(type = "txt", style = 1, char = "=")
Differences_matrix <- apply(country_data_historic_wide[,2:ncol(country_data_historic_wide)],
MARGIN=2,
FUN=function(x){
sapply((PERIOD_FOR_FITTING):length(x),
function(d){Difference_function(x[(d-PERIOD_FOR_FITTING + 1):d])})
}
)
# Format, date and melt the differences matrix to a long dataframe
Differences_matrix = data.frame(Differences_matrix)
Differences_matrix$date = unlist(country_data_historic_wide[PERIOD_FOR_FITTING:nrow(country_data_historic_wide),1],
use.names = FALSE)
diff_vec = reshape2::melt(as_tibble(Differences_matrix), id.vars=c("date"))
# Find and select the end time points of the closes case curves
closest_case_curves <- sort(diff_vec$value,  decreasing = FALSE,index.return=TRUE)$ix[1:NB_OF_CASE_CURVES]
diff_vec2 = diff_vec[closest_case_curves, ]
# Find all the case data before and after the last date of the best fit curves
full_closest_case_curves = sapply(1:NB_OF_CASE_CURVES, function(x){
print(gsub(".", " ", toString(diff_vec2$variable[x]), fixed = TRUE))
unlist(COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING) %>%
dplyr::select(new_cases_smoothed_per_million), use.names = FALSE)
})
# Convert to dataframe, add a time column and melt to long format
full_closest_case_curves <- data.frame(full_closest_case_curves)
full_closest_case_curves
diff_vec2
diff_vec2$variable
gsub(".", " ", toString(diff_vec2$variable[1]), fixed=TRUE)
x=1
unlist(COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING) %>%
dplyr::select(new_cases_smoothed_per_million)
)
unlist(COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING) %>%
dplyr::select(new_cases_smoothed_per_million), use.names = FALSE)
sort(diff_vec$value,  decreasing = FALSE,index.return=TRUE)$ix[1:NB_OF_CASE_CURVES]
sort(diff_vec$value,  decreasing = FALSE,index.return=TRUE)$x[1:NB_OF_CASE_CURVES]
diff_vec2
x=1
COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING)
COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING) %>%
dplyr::select(new_cases_smoothed_per_million)
COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING) %>%
dplyr::select(new_cases_smoothed_per_million)
COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING)
diff_vec$value
sum(is.na(diff_vec$value))
diff_vec2
which.minn(diff_vec$value,  NB_OF_CASE_CURVES)
library(slider)
which.minn(diff_vec$value,  NB_OF_CASE_CURVES)
library(doBy)
which.minn(diff_vec$value,  NB_OF_CASE_CURVES)
diff_vec2 = diff_vec[closest_case_curves, ]
diff_vec2
as.Date(18277)
as.Date(18277, orgin = "1970-01-01")
as.Date(18277, origin = "1970-01-01")
MAX_DATE = as.Date(max_date)
COUNTRY = country
PERIOD_FOR_FITTING = 14
PERIOD_FOR_PREDICTING = 23
NB_OF_CASE_CURVES = 20
DAYS_TO_EVENT = 0
TIME_TO_SYMPTOM_ONSET = 5
TIME_FROM_SYMPT_ONSET_TO_TEST_RESULT = 4
PROPORTION_CASES_DETECTED = 1
# Convert date to numeric
COUNTRY_DATA <- read.csv(file="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv", header=T, sep=",")
COUNTRY_DATA$date <- as.numeric(as.Date(COUNTRY_DATA$date, "%Y-%m-%d"))
# Select the smoothed new cases per million in your country of interest
filename=paste0("prevalence_", COUNTRY, "_data.csv")
chosen_location_data <- COUNTRY_DATA %>%
dplyr::filter((location==COUNTRY) & (date> MAX_DATE - PERIOD_FOR_FITTING) &  (date <= MAX_DATE)) %>%
dplyr::select(new_cases_smoothed_per_million)
# Select all the other data from other countries which might fit your country of interest
country_data_historic <- filter(COUNTRY_DATA, (date < MAX_DATE - PERIOD_FOR_FITTING) &( date> as.Date("2020-03-01")))
# Convert the data to wide format by location name
country_data_historic_wide <- country_data_historic %>%
dplyr::select(date, location, new_cases_smoothed_per_million) %>%
pivot_wider(.,names_from=location, values_from=new_cases_smoothed_per_million)
# Define the difference function
Difference_function <- function(data) {
if(sum(is.na(data))>0){
return(NA)
### might want to
}
sum((data-chosen_location_data$new_cases_smoothed_per_million)^2)
}
# Calculate the differences matrix
pboptions(type = "txt", style = 1, char = "=")
Differences_matrix <- apply(country_data_historic_wide[,2:ncol(country_data_historic_wide)],
MARGIN=2,
FUN=function(x){
sapply((PERIOD_FOR_FITTING):length(x),
function(d){Difference_function(x[(d-PERIOD_FOR_FITTING + 1):d])})
}
)
Differences_matrix = data.frame(Differences_matrix)
Differences_matrix$date = unlist(country_data_historic_wide[PERIOD_FOR_FITTING:nrow(country_data_historic_wide),1],
use.names = FALSE)
diff_vec = reshape2::melt(as_tibble(Differences_matrix), id.vars=c("date"))
# Find and select the end time points of the closes case curves
closest_case_curves <- sort(diff_vec$value,  decreasing = FALSE,index.return=TRUE)$ix[1:NB_OF_CASE_CURVES]
diff_vec2 = diff_vec[closest_case_curves, ]
diff_vec2
# Find all the case data before and after the last date of the best fit curves
full_closest_case_curves = sapply(1:NB_OF_CASE_CURVES, function(x){
print(gsub(".", " ", toString(diff_vec2$variable[x]), fixed = TRUE))
unlist(COUNTRY_DATA %>%
filter(location == gsub(".", " ", toString(diff_vec2$variable[x]), fixed=TRUE),
date >= diff_vec2$date[x] - PERIOD_FOR_FITTING,
date <= diff_vec2$date[x]  +  PERIOD_FOR_PREDICTING) %>%
dplyr::select(new_cases_smoothed_per_million), use.names = FALSE)
})
# Convert to dataframe, add a time column and melt to long format
full_closest_case_curves <- data.frame(full_closest_case_curves)
full_closest_case_curves$time = seq(from=-PERIOD_FOR_FITTING,
to=PERIOD_FOR_PREDICTING,
by=1)
melted_case_curves <- reshape2::melt(full_closest_case_curves,
id.vars="time")
# Calculate the mean and standard deviation at each timepoint
Summarised_case_predictions <- melted_case_curves %>%
group_by(time) %>%
dplyr::summarise(prevalence=mean(value/1e6), sd_prevalence=sd(value/1e6))
# Parametrise the delay between infections and cases being reported
Infection_to_test_result_delay <- TIME_TO_SYMPTOM_ONSET + TIME_FROM_SYMPT_ONSET_TO_TEST_RESULT
#Calculate the date of the cases
Summarised_case_predictions$Date_of_cases=as.Date(Summarised_case_predictions$time +
max(COUNTRY_DATA$date),
origin = "1970-01-01")
# Create a dataframe of infection
Infections_df <- data.frame(Date_of_infection=Summarised_case_predictions$Date_of_cases - Infection_to_test_result_delay,
Infection_prevalence=Summarised_case_predictions$prevalence/PROPORTION_CASES_DETECTED,
sd_Infection_prevalence=Summarised_case_predictions$sd_prevalence/PROPORTION_CASES_DETECTED)
# Reverse sort by date of infection
sorted_case_predictions <- Infections_df[order(Infections_df$Date_of_infection, decreasing=T), ]
# save as csv file
#write.csv(x=sorted_case_predictions, file=filename)
Infection_prevalence
sorted_case_predictions
shiny::runApp('Dropbox/aerosol_transmission_model')
length(SENSITIVITY)
runApp('Dropbox/aerosol_transmission_model')
df <- data.frame(matrix(0,nrow=1000, ncol=15))
names(df) <- c("Age", "Sex", "Pregnant", "Chronic_Renal_Insufficiency" , "Diabetes",
"Immunosuppression", "COPD", "Obesity", "Hypertension", "Tobacco", "Cardiovascular_Disease",
"Asthma", "profession", "high_risk_contact","nb_people_hh")
print("Yata")
t(sapply(1:nrow(df), function(x){
compute_infectiousness_probability(sensitivity = SENSITIVITY,
prevalence=PREVALENCE,
df$profession[x],
df$high_risk_contact[x],
df$nb_people_hh[x]
)
}))
PREVALENCE=0.01
SENSITIVITY
runApp('Dropbox/aerosol_transmission_model')
BREATHING_RATE = 0.012 * 60
DEPOSITION = 0.24
MASK_EFFICIENCY = 0.5  ### 50% is the recommended value
MASK_INHALATION_EFFICIENCY = 0.3
PRESSURE = 0.95
RELATIVE_INFECTIOUSNESS = c(0, 0.01,0.05,0.2,0.6,0.88,0.98,1,1,1,0.95,0.8,0.4,0.2,0.1,0.01)
SENSITIVITY = c(0,0,0.019,0.0327,0.560,0.653,0.718,0.746,0.737,0.718,0.7,0.68,0.662,0.644,0.625)
HOUSEHOLD_TRANSMISSION = 0.5
TAU = 0.06/4
MU = 5
SD = 2
countries = read.csv("population_by_country_2020.csv")
# Define UI for app that draws a histogram ----
library("shiny")
library("tidyverse")
library(gridExtra)
source("proba_adverse_outcome.R")
source("individual_probabilities.R")
source("helper_functions.R")
source("aerosol_functions.R")
source("covid_case_predictions.R")
setwd("~/Dropbox/aerosol_transmission_model/")
countries = read.csv("population_by_country_2020.csv")
BREATHING_RATE = 0.012 * 60
DEPOSITION = 0.24
MASK_EFFICIENCY = 0.5  ### 50% is the recommended value
MASK_INHALATION_EFFICIENCY = 0.3
PRESSURE = 0.95
RELATIVE_INFECTIOUSNESS = c(0, 0.01,0.05,0.2,0.6,0.88,0.98,1,1,1,0.95,0.8,0.4,0.2,0.1,0.01)
SENSITIVITY = c(0,0,0.019,0.0327,0.560,0.653,0.718,0.746,0.737,0.718,0.7,0.68,0.662,0.644,0.625)
HOUSEHOLD_TRANSMISSION = 0.5
TAU = 0.06/4
MU = 5
SD = 2
df <- data.frame(matrix(0,nrow=input$n, ncol=15))
names(df) <- c("Age", "Sex", "Pregnant", "Chronic_Renal_Insufficiency" , "Diabetes",
"Immunosuppression", "COPD", "Obesity", "Hypertension", "Tobacco", "Cardiovascular_Disease",
"Asthma", "profession", "high_risk_contact","nb_people_hh")
print("Yata")
prevalence_df <- compute_prevalence(min(as.Date("2020-00-01"), Sys.Date()),"Estonia")
prevalence_df <- compute_prevalence(min(as.Date("2020-09-01"), Sys.Date()),"Estonia")
#prevalence_df =  read_csv("prevalence_", input$country, "_data.csv")  #rep(0.005,  length(SENSITIVITY)) #extract_prevalence()
filtered_prevalence_df = filter(prevalence_df, Date_of_infection<=as.Date(input$date_event) & Date_of_infection>=as.Date(input$date_event)-14)
#prevalence_df =  read_csv("prevalence_", input$country, "_data.csv")  #rep(0.005,  length(SENSITIVITY)) #extract_prevalence()
filtered_prevalence_df = filter(prevalence_df, Date_of_infection<=as.Date("input$date_event"2020-10-01) & Date_of_infection>=as.Date("2020-01-10")-14)
